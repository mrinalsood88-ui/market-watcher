name: ğŸ” Auto Scrape & Commit Data

on:
  schedule:
    - cron: "0 */6 * * *" # â° Every 6 hours (UTC)
  workflow_dispatch:      # ğŸ§  Allow manual trigger from GitHub Actions tab

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: ğŸ› ï¸ Checkout repository
        uses: actions/checkout@v4
        with:
          persist-credentials: false

      - name: ğŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 22

      - name: ğŸ“¦ Install dependencies
        run: npm ci || npm install

      - name: âš™ï¸ Run Scraper
        env:
          SERP_API_KEY: ${{ secrets.SERP_API_KEY }}
          NEWS_API_KEY: ${{ secrets.NEWS_API_KEY }}
        run: npm run scrape

      - name: ğŸ§­ Verify generated data
        run: |
          echo "Checking output folders..."
          ls -la products || true
          ls -la keywords || true

      - name: ğŸ§© Commit updated JSON files
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add products keywords
          git add .github/workflows/auto-commit.yml || true
          git add scrapers/build_index.mjs || true
          git add scrapers/run_all.mjs || true
          git commit -m "ğŸ” Auto-update data ($(date +'%Y-%m-%d %H:%M:%S'))" || echo "No changes to commit"

      - name: ğŸš€ Push changes
        uses: ad-m/github-push-action@v0.8.0
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          branch: main