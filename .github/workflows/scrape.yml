name: Shopify Scrape & Commit

on:
  schedule:
    - cron: '0 */1 * * *'   # runs every 1 hour (adjust as needed)
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: scrapers

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Clear npm cache
        run: npm cache clean --force

      - name: Install dependencies (using npm install)
        run: npm install

      - name: Run scraper pipeline
        run: |
          node shopify.js
          node diff_shopify_snapshots.js || true
          node build_hot_all.js || true
          node keyword_tracker.js || true

      - name: List outputs
        run: |
          echo "Contents of out directory:"
          ls -lah out || true
          echo "Products:"
          ls -lah out/products || true
          echo "Keywords:"
          ls -lah out/keywords || true

      - name: Commit generated files to repo
        env:
          GIT_AUTHOR_NAME: github-actions[bot]
          GIT_AUTHOR_EMAIL: github-actions[bot]@users.noreply.github.com
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add -A scrapers/out/products || true
          git add -A scrapers/out/keywords || true
          if ! git diff --cached --quiet; then
            git commit -m "chore: update scraper output [ci skip]"
            git push
          else
            echo "No changes to commit."
          fi
