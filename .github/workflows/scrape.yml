name: Scrape and publish

on:
  workflow_dispatch: {}
  schedule:
    - cron: '0 * * * *'   # every hour (UTC)
  push:
    branches: [ main ]

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Install dependencies (scrapers/)
        working-directory: scrapers
        run: |
          if [ -f package-lock.json ]; then
            npm ci
          else
            npm install
          fi
          echo "Installed top-level packages:"
          npm ls --depth=0 || true
          ls -la node_modules | head -20

      - name: Run scraper
        working-directory: scrapers
        run: node run.js

      - name: Copy outputs to repo root
        run: |
          mkdir -p products keywords
          cp -v scrapers/out/products/hot_all.json products/hot_all.json || true
          cp -v scrapers/out/keywords/keyword_hot.json keywords/keyword_hot.json || true
          echo "After copy:"
          ls -R products keywords || true

      - name: Commit & push updates
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add products keywords || true
          if git diff --cached --quiet; then
            echo "No changes to commit"
          else
            git commit -m "chore(ci): update scraper outputs [skip ci]" || true
            git push origin HEAD:main
          fi
