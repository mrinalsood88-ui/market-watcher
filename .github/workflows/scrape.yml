name: Run Market Watcher Scraper + Deploy to GitHub Pages

on:
  schedule:
    - cron: "0 */6 * * *" # every 6 hours
  workflow_dispatch:       # allows manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest

    permissions:
      contents: write  # allow pushing changes
      pages: write
      id-token: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 22

      - name: Install dependencies
        run: npm install

      - name: Run scraper
        env:
          SERP_API_KEY: ${{ secrets.SERP_API_KEY }}
          NEWS_API_KEY: ${{ secrets.NEWS_API_KEY }}
        run: npm run scrape

      - name: Commit scraped data
        run: |
          git config user.name "github-actions"
          git config user.email "actions@github.com"
          git add products/hot_all.json keywords/keyword_hot.json
          git commit -m "Auto-update scraped data [skip ci]" || echo "No changes"
          git push origin main || echo "No push needed"

      - name: Upload artifacts for Pages
        uses: actions/upload-pages-artifact@v3
        with:
          path: .

  deploy:
    runs-on: ubuntu-latest
    needs: scrape
    permissions:
      pages: write
      id-token: write

    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
